{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38883f33",
   "metadata": {},
   "source": [
    "## Phase 1: Understanding and Analyzing the Data\n",
    "\n",
    "### Reading and Understanding the Data\n",
    "- **Explanation:**  \n",
    "  - We load the training and testing data using the Pandas library to understand their structure.  \n",
    "  - We use `pd.read_csv` to read files like `train_feats.csv` and `test_feats.csv`, along with mutation and methylation data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f357592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Checking for missing values:\n",
      "train_muts: 0 missing values\n",
      "test_muts: 0 missing values\n",
      "train_feats: 0 missing values\n",
      "test_feats: 0 missing values\n",
      "train_meth: 0 missing values\n",
      "test_meth: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Phase 1: Data Loading and Exploration\n",
    "print(\"Loading data...\")\n",
    "train_muts = pd.read_csv('train_muts_data.csv')\n",
    "test_muts = pd.read_csv('test_muts_data.csv')\n",
    "train_feats = pd.read_csv('train_feats.csv')\n",
    "test_feats = pd.read_csv('test_feats.csv')\n",
    "genes_100 = pd.read_csv('100_genes.csv')\n",
    "train_meth = pd.read_csv('train_meth_data.csv')\n",
    "test_meth = pd.read_csv('test_meth_data.csv')\n",
    "\n",
    "# Check for missing values in all datasets\n",
    "print(\"Checking for missing values:\")\n",
    "for df, name in [(train_muts, 'train_muts'), (test_muts, 'test_muts'), (train_feats, 'train_feats'), \n",
    "                (test_feats, 'test_feats'), (train_meth, 'train_meth'), (test_meth, 'test_meth')]:\n",
    "    print(f\"{name}: {df.isnull().sum().sum()} missing values\")\n",
    "\n",
    "# Verify that genes in mutation and methylation data are in 100_genes.csv\n",
    "gene_set = set(genes_100['gene'])\n",
    "assert set(train_muts['Gene_name']).issubset(gene_set), \"Mutation genes not in 100_genes\"\n",
    "assert set(train_meth['matching_genes']).issubset(gene_set), \"Methylation genes not in 100_genes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e1b48",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "- **Explanation:**  \n",
    "  - We examine the distribution of labels in the training data to check for class balance using `value_counts()`.  \n",
    "  - We check for missing values using `isnull().sum()` to ensure data quality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29529662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution in Training Data:\n",
      "Label\n",
      "2.0    408\n",
      "1.0    397\n",
      "Name: count, dtype: int64\n",
      "Missing Values in Training Features:\n",
      "case_id               0\n",
      "Label                 0\n",
      "Mutations_in_ABL1     0\n",
      "Mutations_in_AKT1     0\n",
      "Mutations_in_ALK      0\n",
      "                     ..\n",
      "Mutations_in_TSC1     0\n",
      "Mutations_in_TSC2     0\n",
      "Mutations_in_U2AF1    0\n",
      "Mutations_in_VHL      0\n",
      "Mutations_in_WT1      0\n",
      "Length: 102, dtype: int64\n",
      "Missing Values in Testing Features:\n",
      "case_id               0\n",
      "Mutations_in_ABL1     0\n",
      "Mutations_in_AKT1     0\n",
      "Mutations_in_ALK      0\n",
      "Mutations_in_APC      0\n",
      "                     ..\n",
      "Mutations_in_TSC1     0\n",
      "Mutations_in_TSC2     0\n",
      "Mutations_in_U2AF1    0\n",
      "Mutations_in_VHL      0\n",
      "Mutations_in_WT1      0\n",
      "Length: 101, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display label distribution and missing values in feature files\n",
    "print(\"Label Distribution in Training Data:\")\n",
    "print(train_feats['Label'].value_counts())\n",
    "print(\"Missing Values in Training Features:\")\n",
    "print(train_feats.isnull().sum())\n",
    "print(\"Missing Values in Testing Features:\")\n",
    "print(test_feats.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19fd8c",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b18c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mutation features...\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Feature Creation for Task 1\n",
    "print(\"Creating mutation features...\")\n",
    "# Total mutations per patient\n",
    "train_total_muts = train_muts.groupby('case_id').size().reset_index(name='Total_Mutations')\n",
    "test_total_muts = test_muts.groupby('case_id').size().reset_index(name='Total_Mutations')\n",
    "\n",
    "# Mutations per variant classification\n",
    "train_var_counts = train_muts.groupby(['case_id', 'Variant_Classification']).size().unstack(fill_value=0)\n",
    "train_var_counts.columns = [f'Mutations_{col}' for col in train_var_counts.columns]\n",
    "test_var_counts = test_muts.groupby(['case_id', 'Variant_Classification']).size().unstack(fill_value=0)\n",
    "test_var_counts.columns = [f'Mutations_{col}' for col in test_var_counts.columns]\n",
    "\n",
    "# Mutations per variant classification per gene\n",
    "train_gene_var = train_muts.groupby(['case_id', 'Gene_name', 'Variant_Classification']).size().unstack(level=[1, 2], fill_value=0)\n",
    "train_gene_var.columns = [f'Mutations_in_{gene}_{var}' for gene, var in train_gene_var.columns]\n",
    "test_gene_var = test_muts.groupby(['case_id', 'Gene_name', 'Variant_Classification']).size().unstack(level=[1, 2], fill_value=0)\n",
    "test_gene_var.columns = [f'Mutations_in_{gene}_{var}' for gene, var in test_gene_var.columns]\n",
    "\n",
    "# Additional feature: Mutation types (Transition, Transversion, Insertion, Deletion, Other)\n",
    "# Justification: Different mutation types may indicate distinct biological mechanisms in cancer\n",
    "def classify_mutation(row):\n",
    "    ref, tumor = row['Reference_Allele'], row['Tumor_Seq_Allele1']\n",
    "    if len(ref) == len(tumor) == 1:\n",
    "        transitions = {('A', 'G'), ('G', 'A'), ('C', 'T'), ('T', 'C')}\n",
    "        return 'Transition' if (ref, tumor) in transitions else 'Transversion'\n",
    "    elif len(ref) > len(tumor):\n",
    "        return 'Deletion'\n",
    "    elif len(ref) < len(tumor):\n",
    "        return 'Insertion'\n",
    "    return 'Other'\n",
    "\n",
    "train_muts['Mut_Type'] = train_muts.apply(classify_mutation, axis=1)\n",
    "test_muts['Mut_Type'] = test_muts.apply(classify_mutation, axis=1)\n",
    "train_mut_types = train_muts.groupby(['case_id', 'Mut_Type']).size().unstack(fill_value=0)\n",
    "train_mut_types.columns = [f'Mutations_{col}' for col in train_mut_types.columns]\n",
    "test_mut_types = test_muts.groupby(['case_id', 'Mut_Type']).size().unstack(fill_value=0)\n",
    "test_mut_types.columns = [f'Mutations_{col}' for col in test_mut_types.columns]\n",
    "\n",
    "# Additional feature: Strand bias\n",
    "# Justification: Strand bias may reveal preferences in mutation or DNA repair mechanisms\n",
    "train_strand = train_muts.groupby('case_id')['Mut_Strand'].apply(lambda x: (x == '+').mean()).reset_index(name='Strand_Bias')\n",
    "test_strand = test_muts.groupby('case_id')['Mut_Strand'].apply(lambda x: (x == '+').mean()).reset_index(name='Strand_Bias')\n",
    "\n",
    "# Additional feature: Normalized mutation rate\n",
    "# Justification: Normalizing by gene length accounts for bias due to varying gene sizes\n",
    "genes_100['Length'] = genes_100['Sequence'].str.len()\n",
    "train_norm_muts = train_muts.groupby(['case_id', 'Gene_name']).size().reset_index(name='Count')\n",
    "train_norm_muts = train_norm_muts.merge(genes_100[['gene', 'Length']], left_on='Gene_name', right_on='gene')\n",
    "train_norm_muts['Norm_Mutations'] = train_norm_muts['Count'] / train_norm_muts['Length']\n",
    "train_norm_muts = train_norm_muts.pivot(index='case_id', columns='Gene_name', values='Norm_Mutations').fillna(0)\n",
    "train_norm_muts.columns = [f'Norm_Mutations_in_{col}' for col in train_norm_muts.columns]\n",
    "test_norm_muts = test_muts.groupby(['case_id', 'Gene_name']).size().reset_index(name='Count')\n",
    "test_norm_muts = test_norm_muts.merge(genes_100[['gene', 'Length']], left_on='Gene_name', right_on='gene')\n",
    "test_norm_muts['Norm_Mutations'] = test_norm_muts['Count'] / test_norm_muts['Length']\n",
    "test_norm_muts = test_norm_muts.pivot(index='case_id', columns='Gene_name', values='Norm_Mutations').fillna(0)\n",
    "test_norm_muts.columns = [f'Norm_Mutations_in_{col}' for col in test_norm_muts.columns]\n",
    "\n",
    "# Combine all mutation features\n",
    "train_features = train_total_muts.set_index('case_id').join([train_var_counts, train_gene_var, train_mut_types, \n",
    "                                                            train_strand.set_index('case_id'), train_norm_muts]).reset_index()\n",
    "test_features = test_total_muts.set_index('case_id').join([test_var_counts, test_gene_var, test_mut_types, \n",
    "                                                        test_strand.set_index('case_id'), test_norm_muts]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e30037",
   "metadata": {},
   "source": [
    "---\n",
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph...\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Graph Creation\n",
    "print(\"Creating graph...\")\n",
    "var_totals = train_muts['Variant_Classification'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "var_totals.plot(kind='bar')\n",
    "plt.xlabel('Variant Classification')\n",
    "plt.ylabel('Number of Mutations')\n",
    "plt.title('Mutation Distribution by Variant Type')\n",
    "plt.savefig('mutation_distribution.png')\n",
    "plt.show('mutation_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b739d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Task 1 classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okal/Zone/Rebos/Computational-Genomics/.venv/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [1001] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/okal/Zone/Rebos/Computational-Genomics/.venv/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Phase 4: Classifier for Task 1\n",
    "print(\"Training Task 1 classifier...\")\n",
    "# Merge features with labels\n",
    "train_data = train_features.merge(train_feats[['case_id', 'Label']], on='case_id')\n",
    "\n",
    "# Prepare training and test features\n",
    "X_train = train_data.drop(columns=['case_id', 'Label']).fillna(0)\n",
    "y_train = train_data['Label']\n",
    "X_test = test_features.drop(columns=['case_id']).fillna(0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Feature selection: Select top 50 features using SelectKBest\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Split data for validation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_selected, y_train, test_size=0.2, \n",
    "                                                            stratify=y_train, random_state=42)\n",
    "\n",
    "# Define and train SVM with expanded grid search\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'degree': [2, 3, 4], 'gamma': ['scale', 'auto', 0.1, 1]}\n",
    "svm = SVC(kernel='poly', random_state=42)\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Output results\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "y_val_pred = grid_search.predict(X_val)\n",
    "error = (y_val_pred != y_val).mean()\n",
    "print(f\"Validation error: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data and predict on test set\n",
    "svm_final = SVC(kernel='poly', C=grid_search.best_params_['C'], degree=grid_search.best_params_['degree'], \n",
    "                gamma=grid_search.best_params_['gamma'], random_state=42)\n",
    "svm_final.fit(X_train_selected, y_train)\n",
    "y_test_pred = svm_final.predict(X_test_selected)\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({'id_case': test_features['case_id'], 'label_predict': y_test_pred}).to_csv('task1_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45261b1e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b204c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating methylation features...\n"
     ]
    }
   ],
   "source": [
    "# Phase 5: Feature Creation for Task 2\n",
    "print(\"Creating methylation features...\")\n",
    "# Required feature: Average methylation per gene\n",
    "train_meth_avg = train_meth.groupby(['case_id', 'matching_genes'])['beta_val'].mean().unstack(fill_value=0)\n",
    "train_meth_avg.columns = [f'Meth_Avg_{col}' for col in train_meth_avg.columns]\n",
    "test_meth_avg = test_meth.groupby(['case_id', 'matching_genes'])['beta_val'].mean().unstack(fill_value=0)\n",
    "test_meth_avg.columns = [f'Meth_Avg_{col}' for col in test_meth_avg.columns]\n",
    "\n",
    "# Additional feature: Standard deviation of methylation values\n",
    "# Justification: Captures variability in methylation levels, which may indicate heterogeneous epigenetic patterns\n",
    "train_meth_std = train_meth.groupby(['case_id', 'matching_genes'])['beta_val'].std().unstack(fill_value=0)\n",
    "train_meth_std.columns = [f'Meth_Std_{col}' for col in train_meth_std.columns]\n",
    "test_meth_std = test_meth.groupby(['case_id', 'matching_genes'])['beta_val'].std().unstack(fill_value=0)\n",
    "test_meth_std.columns = [f'Meth_Std_{col}' for col in test_meth_std.columns]\n",
    "\n",
    "# Additional feature: Proportion of high-methylation sites (beta_val > 0.7)\n",
    "# Justification: High methylation levels may be associated with gene silencing in cancer\n",
    "train_meth_high = train_meth[train_meth['beta_val'] > 0.7].groupby(['case_id', 'matching_genes']).size().unstack(fill_value=0)\n",
    "train_meth_high = train_meth_high.div(train_meth.groupby(['case_id', 'matching_genes']).size().unstack(fill_value=1)).fillna(0)\n",
    "train_meth_high.columns = [f'Meth_High_Prop_{col}' for col in train_meth_high.columns]\n",
    "test_meth_high = test_meth[test_meth['beta_val'] > 0.7].groupby(['case_id', 'matching_genes']).size().unstack(fill_value=0)\n",
    "test_meth_high = test_meth_high.div(test_meth.groupby(['case_id', 'matching_genes']).size().unstack(fill_value=1)).fillna(0)\n",
    "test_meth_high.columns = [f'Meth_High_Prop_{col}' for col in test_meth_high.columns]\n",
    "\n",
    "# Combine mutation and methylation features\n",
    "train_combined = train_features.set_index('case_id').join([train_meth_avg, train_meth_std, train_meth_high]).reset_index()\n",
    "test_combined = test_features.set_index('case_id').join([test_meth_avg, test_meth_std, test_meth_high]).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f0511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Task 2 classifier...\n",
      "Best params: {'C': 10, 'degree': 2}\n",
      "Validation error: 0.37888198757763975\n",
      "Task 2 completed. Predictions saved.\n"
     ]
    }
   ],
   "source": [
    "# Phase 6: Classifier for Task 2\n",
    "print(\"Training Task 2 classifier...\")\n",
    "# Prepare training and test features\n",
    "X_train_combined = train_combined.drop(columns=['case_id']).fillna(0)\n",
    "X_test_combined = test_combined.drop(columns=['case_id']).fillna(0)\n",
    "X_test_combined = X_test_combined.reindex(columns=X_train_combined.columns, fill_value=0)\n",
    "\n",
    "# Feature selection: Select top 50 features\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "X_train_combined_selected = selector.fit_transform(X_train_combined, y_train)\n",
    "X_test_combined_selected = selector.transform(X_test_combined)\n",
    "\n",
    "# Split data for validation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_combined_selected, y_train, test_size=0.2, \n",
    "                                                            stratify=y_train, random_state=42)\n",
    "\n",
    "# Train SVM with expanded grid search\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Output results\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "y_val_pred = grid_search.predict(X_val)\n",
    "error = (y_val_pred != y_val).mean()\n",
    "print(f\"Validation error: {error}\")\n",
    "\n",
    "# Train final model and predict on test set\n",
    "svm_final = SVC(kernel='poly', C=grid_search.best_params_['C'], degree=grid_search.best_params_['degree'], \n",
    "                gamma=grid_search.best_params_['gamma'], random_state=42)\n",
    "svm_final.fit(X_train_combined_selected, y_train)\n",
    "y_test_pred = svm_final.predict(X_test_combined_selected)\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({'id_case': test_combined['case_id'], 'label_predict': y_test_pred}).to_csv('task2_predictions.csv', index=False)\n",
    "\n",
    "print(\"Project completed. Predictions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
